{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0\n",
      "[[ 0.26894167]\n",
      " [ 0.50097865]\n",
      " [ 0.48343664]\n",
      " [ 0.71862179]]\n",
      "Step 500\n",
      "[[  8.66338834e-10]\n",
      " [  8.75853526e-04]\n",
      " [  8.75625759e-04]\n",
      " [  9.98873651e-01]]\n",
      "Step 1000\n",
      "[[  3.46256045e-11]\n",
      " [  2.99638894e-04]\n",
      " [  2.99561216e-04]\n",
      " [  9.99614596e-01]]\n",
      "Step 1500\n",
      "[[  4.48026859e-12]\n",
      " [  1.51575194e-04]\n",
      " [  1.51535583e-04]\n",
      " [  9.99805033e-01]]\n",
      "Step 2000\n",
      "[[  9.43163191e-13]\n",
      " [  9.01826425e-05]\n",
      " [  9.01592575e-05]\n",
      " [  9.99884009e-01]]\n",
      "Step 2500\n",
      "[[  2.57996017e-13]\n",
      " [  5.85423913e-05]\n",
      " [  5.85272101e-05]\n",
      " [  9.99924660e-01]]\n",
      "Step 3000\n",
      "[[  8.28307624e-14]\n",
      " [  4.00874633e-05]\n",
      " [  4.00769932e-05]\n",
      " [  9.99948502e-01]]\n",
      "Step 3500\n",
      "[[  2.95503334e-14]\n",
      " [  2.84311009e-05]\n",
      " [  2.84237267e-05]\n",
      " [  9.99963403e-01]]\n",
      "Step 4000\n",
      "[[  1.13384957e-14]\n",
      " [  2.06601926e-05]\n",
      " [  2.06548357e-05]\n",
      " [  9.99973416e-01]]\n",
      "Step 4500\n",
      "[[  4.58230213e-15]\n",
      " [  1.52748034e-05]\n",
      " [  1.52708417e-05]\n",
      " [  9.99980330e-01]]\n",
      "Step 5000\n",
      "[[  1.92341531e-15]\n",
      " [  1.14375725e-05]\n",
      " [  1.14346067e-05]\n",
      " [  9.99985337e-01]]\n",
      "Step 5500\n",
      "[[  8.30206426e-16]\n",
      " [  8.64301455e-06]\n",
      " [  8.64075537e-06]\n",
      " [  9.99988914e-01]]\n",
      "Step 6000\n",
      "[[  3.65991184e-16]\n",
      " [  6.57825740e-06]\n",
      " [  6.57655164e-06]\n",
      " [  9.99991536e-01]]\n",
      "Step 6500\n",
      "[[  1.63933208e-16]\n",
      " [  5.03338242e-06]\n",
      " [  5.03206775e-06]\n",
      " [  9.99993563e-01]]\n",
      "Step 7000\n",
      "[[  7.43179098e-17]\n",
      " [  3.86563443e-06]\n",
      " [  3.86460988e-06]\n",
      " [  9.99994993e-01]]\n",
      "Step 7500\n",
      "[[  3.40082173e-17]\n",
      " [  2.97874726e-06]\n",
      " [  2.97796919e-06]\n",
      " [  9.99996185e-01]]\n",
      "Step 8000\n",
      "[[  1.56710972e-17]\n",
      " [  2.29878492e-06]\n",
      " [  2.29818875e-06]\n",
      " [  9.99997020e-01]]\n",
      "Step 8500\n",
      "[[  7.26553098e-18]\n",
      " [  1.77931770e-06]\n",
      " [  1.77885283e-06]\n",
      " [  9.99997735e-01]]\n",
      "Step 9000\n",
      "[[  3.38013916e-18]\n",
      " [  1.37486415e-06]\n",
      " [  1.37452071e-06]\n",
      " [  9.99998212e-01]]\n",
      "Step 9500\n",
      "[[  1.58487402e-18]\n",
      " [  1.07446488e-06]\n",
      " [  1.07417804e-06]\n",
      " [  9.99998569e-01]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f60101bf438>]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6013ed0898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_input = tf.placeholder(tf.float32, shape = [4, 2], name = \"input\")\n",
    "y_output = tf.placeholder(tf.float32, shape = [4, 1], name = \"output\")\n",
    "weights = tf.Variable(tf.random_uniform([2, 1], -1, 1), name = \"weights\")\n",
    "bias = tf.Variable(tf.zeros([1]), name = \"bias\")\n",
    "hypothesis = tf.sigmoid(tf.matmul(x_input, weights) + bias)\n",
    "cost = tf.reduce_mean(((y_output * tf.log(hypothesis)) + ((1 - y_output) * tf.log(1.0 - hypothesis)) ) * -1)\n",
    "train_step = tf.train.AdamOptimizer(1).minimize(cost)\n",
    "AND_X = [[0, 0], [0, 1], [1, 0], [1, 1]]\n",
    "AND_Y = [[0], [0], [0], [1]]\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "costs = []\n",
    "for i in range(10000):\n",
    "    sess.run(train_step, feed_dict = {x_input: AND_X, y_output: AND_Y})\n",
    "    if i % 500 == 0:\n",
    "        print(\"Step \" + str(i))\n",
    "        print(sess.run(hypothesis, feed_dict = {x_input: AND_X, y_output: AND_Y}))\n",
    "        current_cost = sess.run(cost, feed_dict = {x_input: AND_X, y_output: AND_Y})\n",
    "        costs.append(current_cost)\n",
    "plt.plot(range(len(costs)), costs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.49983644,\n",
       " 0.00071980839,\n",
       " 0.00024619332,\n",
       " 0.00012452459,\n",
       " 7.4092291e-05,\n",
       " 4.8102516e-05,\n",
       " 3.2917396e-05,\n",
       " 2.3365392e-05,\n",
       " 1.698752e-05,\n",
       " 1.2546884e-05]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "costs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### tf example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot = True)\n",
    "\n",
    "# Model preparation\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "display_step = 1\n",
    "\n",
    "n_hidden_1 = 256 # 1st layer number of features\n",
    "n_hidden_2 = 256 # 2nd layer number of features\n",
    "n_input = 784\n",
    "n_classes = 10\n",
    "x = tf.placeholder(\"float\", [None, n_input])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    layer_1 = tf.nn.relu(tf.add(tf.matmul(x, weights[\"h1\"]), biases[\"b1\"])) # ReLU\n",
    "    layer_2 = tf.nn.relu(tf.add(tf.matmul(layer_1, weights[\"h2\"]), biases[\"b2\"])) # ReLU\n",
    "    out_layer = tf.matmul(layer_2, weights[\"out\"]) + biases[\"out\"] # Purely linear activation\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model initialization\n",
    "weights = {\n",
    "    \"h1\": tf.Variable(tf.random_normal([n_input, n_hidden_1])),\n",
    "    \"h2\": tf.Variable(tf.random_normal([n_hidden_1, n_hidden_2])),\n",
    "    \"out\": tf.Variable(tf.random_normal([n_hidden_2, n_classes]))\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    \"b1\": tf.Variable(tf.random_normal([n_hidden_1])),\n",
    "    \"b2\": tf.Variable(tf.random_normal([n_hidden_2])),\n",
    "    \"out\": tf.Variable(tf.random_normal([n_classes]))\n",
    "}\n",
    "pred = multilayer_perceptron(x, weights, biases)\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = pred, labels = y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 cost= 152.540153327\n",
      "Epoch: 0002 cost= 40.969139039\n",
      "Epoch: 0003 cost= 25.576778047\n",
      "Epoch: 0004 cost= 17.494725654\n",
      "Epoch: 0005 cost= 12.491557414\n",
      "Epoch: 0006 cost= 9.297886864\n",
      "Epoch: 0007 cost= 6.767272083\n",
      "Epoch: 0008 cost= 4.923767798\n",
      "Epoch: 0009 cost= 3.683918091\n",
      "Epoch: 0010 cost= 2.718031013\n",
      "Epoch: 0011 cost= 1.946386597\n",
      "Epoch: 0012 cost= 1.530443200\n",
      "Epoch: 0013 cost= 1.122690888\n",
      "Epoch: 0014 cost= 0.903676396\n",
      "Epoch: 0015 cost= 0.749515452\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9468\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(training_epochs):\n",
    "        avg_cost = 0.\n",
    "        total_batch = int(mnist.train.num_examples / batch_size)\n",
    "        for i in range(total_batch):\n",
    "            batch_x, batch_y = mnist.train.next_batch(batch_size)\n",
    "            _, c = sess.run([optimizer, cost], feed_dict={x: batch_x, y: batch_y})\n",
    "            avg_cost += c / total_batch\n",
    "        # Display logs per epoch step\n",
    "        if epoch % display_step == 0:\n",
    "            print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(avg_cost))\n",
    "    print(\"Optimization Finished!\")\n",
    "    \n",
    "    # Test model\n",
    "    correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "    # Calculate accuracy\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "    print(\"Accuracy:\", accuracy.eval({x: mnist.test.images, y: mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
